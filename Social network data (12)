# Load necessary libraries
library(dplyr)
library(haven)  # For handling labelled data

# Assuming 'social_networks_2018' is the dataset already loaded in your R environment
data <- social_networks_2018

# Define the variable ranges
relationship_vars <- paste0("wj18a", 139:163)    # Relationships
closeness_vars <- paste0("wj18a", 165:189)       # Closeness
face_to_face_vars <- paste0("wj18a", 217:241)    # Face-to-face contact
children_vars <- paste0("wj18a", 295:319)        # Has children/expecting
happiness_vars <- paste0("wj18a", 372:396)       # Happiness change
babysitter_vars <- paste0("wj18a", 450:474)      # Babysitter help
discuss_children_vars <- paste0("wj18a", 476:500) # Discuss children
mutual_contact_vars <- paste0("wj18a", 502:526)  # Mutual contact

# Convert all relevant columns to numeric, coercing invalid values to NA
convert_to_numeric <- function(x) {
  as.numeric(as.character(x))  # Convert haven_labelled or character to numeric
}

data[relationship_vars] <- lapply(data[relationship_vars], convert_to_numeric)
data[closeness_vars] <- lapply(data[closeness_vars], convert_to_numeric)
data[face_to_face_vars] <- lapply(data[face_to_face_vars], convert_to_numeric)
data[children_vars] <- lapply(data[children_vars], convert_to_numeric)
data[happiness_vars] <- lapply(data[happiness_vars], convert_to_numeric)
data[babysitter_vars] <- lapply(data[babysitter_vars], convert_to_numeric)
data[discuss_children_vars] <- lapply(data[discuss_children_vars], convert_to_numeric)
data[mutual_contact_vars] <- lapply(data[mutual_contact_vars], convert_to_numeric)

# Summarize all variables
aggregated_data <- data %>%
  rowwise() %>%
  summarise(
    ID = nomem_encr,  # Keep ID
    
    # Relationship counts
    Partner_Count = sum(c_across(all_of(relationship_vars)) == 1, na.rm = TRUE),
    Parent_Count = sum(c_across(all_of(relationship_vars)) == 2, na.rm = TRUE),
    Sibling_Count = sum(c_across(all_of(relationship_vars)) == 3, na.rm = TRUE),
    Work_Count = sum(c_across(all_of(relationship_vars)) == 10, na.rm = TRUE),
    Social_Activity_Count = sum(c_across(all_of(relationship_vars)) == 11, na.rm = TRUE),

    # Average bond closeness for each relationship type
    Partner_Closeness = mean(c_across(all_of(closeness_vars))[c_across(all_of(relationship_vars)) == 1], na.rm = TRUE),
    Parent_Closeness = mean(c_across(all_of(closeness_vars))[c_across(all_of(relationship_vars)) == 2], na.rm = TRUE),
    Sibling_Closeness = mean(c_across(all_of(closeness_vars))[c_across(all_of(relationship_vars)) == 3], na.rm = TRUE),
    Work_Closeness = mean(c_across(all_of(closeness_vars))[c_across(all_of(relationship_vars)) == 10], na.rm = TRUE),
    Social_Activity_Closeness = mean(c_across(all_of(closeness_vars))[c_across(all_of(relationship_vars)) == 11], na.rm = TRUE),

    # Face-to-face contact frequency
    Face_to_Face_Contact_Avg = mean(c_across(all_of(face_to_face_vars)), na.rm = TRUE),

    # Has children/expecting
    Has_Children_Count = sum(c_across(all_of(children_vars)) == 1, na.rm = TRUE),

    # Happiness change after childbirth
    Happiness_Change_Avg = mean(c_across(all_of(happiness_vars)), na.rm = TRUE),

    # Babysitter help count
    Babysitter_Help_Count = sum(c_across(all_of(babysitter_vars)) == 1, na.rm = TRUE),

    # Discuss children count
    Discuss_Children_Count = sum(c_across(all_of(discuss_children_vars)) == 1, na.rm = TRUE),

    # Mutual contact count
    Mutual_Contact_Count = sum(c_across(all_of(mutual_contact_vars)) == 1, na.rm = TRUE)
  )

# View the aggregated data
head(aggregated_data)

# Save the aggregated data back to a file
write.csv(aggregated_data, "final_aggregated_relationships.csv", row.names = FALSE)
cat("Final aggregated dataset saved as 'final_aggregated_relationships.csv'\n")








library(dplyr)
library(caret)
library(ROSE)
library(pROC)

# Define variable groups
numerical_vars <- c("age")
ordinal_vars <- c("family_satisfaction", "future_children", "social_contacts_satisfaction", "work_satisfaction", "colleague_atmosphere_satisfaction")
categorical_vars <- c("shared_friends", "partner", "church_member", "sports_club_member", "political_party_member", "primary_occupation")

# Step 1: Preprocessing
preprocess_KNN <- function(data) {
  data <- data %>%
    # Exclude irrelevant variables (but keep ID for later use)
    select(-c(gender, birth_year_first_child)) %>%
    # Scale numerical and ordinal variables
    mutate(across(all_of(c(numerical_vars, ordinal_vars)), ~ scale(.))) %>%
    # One-hot encode categorical variables
    {
      dummies <- dummyVars(~ ., data = .[, categorical_vars], fullRank = TRUE)
      encoded_categorical <- as.data.frame(predict(dummies, newdata = .))
      bind_cols(select(., -all_of(categorical_vars)), encoded_categorical)
    }
  return(data)
}

# Apply preprocessing (keep ID column for validation_data)
preprocessed_data <- preprocess_KNN(preprocessed_data)

# Step 2: Separate Target Variable
target_var <- "yes_no_baby"
predictors <- setdiff(names(preprocessed_data), c(target_var, "year", "ID"))

# Step 3: Split Data (Retain ID for validation_data)
train_data <- preprocessed_data %>% filter(year >= 2007 & year <= 2016)
validation_data <- preprocessed_data %>% filter(year >= 2017 & year <= 2018) %>% select(ID, everything())
test_data <- preprocessed_data %>% filter(year >= 2019 & year <= 2022)

# View the updated validation_data to confirm ID retention
head(validation_data)









# Ensure ID columns are consistent in both datasets
validation_data$ID <- as.character(validation_data$ID)
aggregated_data$ID <- as.character(aggregated_data$ID)

# Merge the datasets by ID
validation_merged <- merge(validation_data, aggregated_data, by = "ID", all.x = TRUE)

# View the merged data
head(validation_merged)





# Ensure ID columns are consistent
test_data$ID <- as.character(test_data$ID)
aggregated_data$ID <- as.character(aggregated_data$ID)

# Merge test_data with aggregated_data
test_merged <- merge(test_data, aggregated_data, by = "ID", all.x = TRUE)

# View the merged test_data
head(test_merged)





library(dplyr)

# Function to calculate weighted KNN
weighted_knn <- function(X_train, y_train, X_test, k, class_weights) {
  # Initialize predictions
  predictions <- vector("character", nrow(X_test))
  
  # Loop through each test instance
  for (i in seq_len(nrow(X_test))) {
    # Calculate distances between test instance and all training instances
    distances <- sqrt(rowSums((t(t(X_train) - X_test[i, ]))^2))
    
    # Get the indices of the k-nearest neighbors
    nearest_indices <- order(distances)[1:k]
    
    # Extract classes of the nearest neighbors
    neighbor_classes <- y_train[nearest_indices]
    
    # Apply class weights
    neighbor_weights <- class_weights[as.character(neighbor_classes)]
    
    # Aggregate weighted votes
    weighted_votes <- aggregate(neighbor_weights, by = list(Class = neighbor_classes), FUN = sum)
    colnames(weighted_votes) <- c("Class", "WeightedVotes")
    
    # Predict the class with the highest weighted vote
    predictions[i] <- weighted_votes$Class[which.max(weighted_votes$WeightedVotes)]
  }
  
  return(factor(predictions, levels = levels(y_train)))
}

# Define predictors and target
predictors <- setdiff(names(validation_merged), c("ID", "year", "yes_no_baby"))  # Exclude non-predictive columns
target <- "yes_no_baby"

# Separate features (X) and target (y)
X_validation <- validation_merged[, predictors]
y_validation <- validation_merged[, target]

X_test <- test_merged[, predictors]
y_test <- test_merged[, target]

# Handle missing values with imputation
preprocess <- preProcess(X_validation, method = c("medianImpute"))
X_validation <- predict(preprocess, newdata = X_validation)
X_test <- predict(preprocess, newdata = X_test)

# Calculate class weights
class_distribution <- table(y_validation)
class_weights <- max(class_distribution) / class_distribution
names(class_weights) <- levels(y_validation)

cat("Class Weights:\n")
print(class_weights)

# Apply custom weighted KNN
k <- 5  # Choose number of neighbors
knn_predictions <- weighted_knn(X_train = X_validation, y_train = y_validation, X_test = X_test, k = k, class_weights = class_weights)

# Confusion Matrix
confusion_matrix <- table(Predicted = knn_predictions, Actual = y_test)
cat("Confusion Matrix:\n")
print(confusion_matrix)

# Calculate Metrics
true_positives <- if ("Yes" %in% rownames(confusion_matrix) & "Yes" %in% colnames(confusion_matrix)) 
  confusion_matrix["Yes", "Yes"] else 0
true_negatives <- if ("No" %in% rownames(confusion_matrix) & "No" %in% colnames(confusion_matrix)) 
  confusion_matrix["No", "No"] else 0
false_positives <- if ("Yes" %in% rownames(confusion_matrix) & "No" %in% colnames(confusion_matrix)) 
  confusion_matrix["Yes", "No"] else 0
false_negatives <- if ("No" %in% rownames(confusion_matrix) & "Yes" %in% colnames(confusion_matrix)) 
  confusion_matrix["No", "Yes"] else 0

# Precision
precision <- if ((true_positives + false_positives) > 0) 
  true_positives / (true_positives + false_positives) else NA

# Recall
recall <- if ((true_positives + false_negatives) > 0) 
  true_positives / (true_positives + false_negatives) else NA

# F1-Score
f1_score <- if (!is.na(precision) & !is.na(recall) & (precision + recall) > 0) 
  2 * (precision * recall) / (precision + recall) else NA

# MSE
knn_predictions_binary <- ifelse(knn_predictions == "Yes", 1, 0)
y_test_binary <- ifelse(y_test == "Yes", 1, 0)
mse <- mean((knn_predictions_binary - y_test_binary)^2, na.rm = TRUE)

# Print Metrics
cat("Precision: ", precision, "\n")
cat("Recall: ", recall, "\n")
cat("F1-Score: ", f1_score, "\n")
cat("Mean Squared Error (MSE): ", mse, "\n")

